{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "def dataread(input,write=False,writeData=None):\n",
    "    file_type=input.split('.')[-1]\n",
    "    if file_type == 'xlsx':\n",
    "        file=pd.read_excel(input)\n",
    "    elif file_type == 'txt':\n",
    "        file=pd.read_csv(input,sep='\\t')\n",
    "    elif file_type == 'csv':\n",
    "        file=pd.read_csv(input)\n",
    "    return file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HPO=pd.read_csv('DBHPO.csv')\n",
    "#OMIM=pd.read_csv('DBOMIM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMIM_new=pd.read_csv('08_26_all_omim_phenotype_translation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  uniq the omim datasate and add chinesed omim description in to colums, generate the format that we need \n",
    "OMIM_cn=[]\n",
    "OMIM_en=[]\n",
    "geneSymbol=[]\n",
    "inheritance=[]\n",
    "\n",
    "i=0\n",
    "for i in range(len(OMIM_new['Phenotype MIM number'])):\n",
    "    des_en= OMIM_new['Phenotype'][i]+'(OMIM:'+ str(OMIM_new['Phenotype MIM number'][i])+', '+str(OMIM_new['Inheritance'][i]) + ')'\n",
    "    des_cn= OMIM_new['Translation_Phenotype'][i] +'(OMIM:'+ str(OMIM_new['Phenotype MIM number'][i]) +', '+str(OMIM_new['Inheritance'][i])+ ')'\n",
    "    symbol= OMIM_new['Gene/Locus'][i]\n",
    "    inher = OMIM_new['Inheritance'][i]\n",
    "    OMIM_en.append(des_en)\n",
    "    OMIM_cn.append(des_cn)\n",
    "    geneSymbol.append(symbol)\n",
    "    inheritance.append(inher)\n",
    "new_OMIM={'Gene':geneSymbol,'OMIM_en':OMIM_en,'OMIM_cn':OMIM_cn}\n",
    "OMIM_trans=pd.DataFrame(new_OMIM)\n",
    "geneSymbol_uniq=list(set(geneSymbol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the database format \n",
    "dict={}\n",
    "description_save_en=[]\n",
    "description_save_cn=[]\n",
    "geneName=[]\n",
    "for i in range(len(geneSymbol_uniq)):\n",
    "    my_tmp=''\n",
    "    my_tmp_cn=''\n",
    "    for k in range(len(geneSymbol)):\n",
    "        if OMIM_trans['Gene'][k]==geneSymbol_uniq[i] :\n",
    "            my_tmp+=OMIM_trans['OMIM_en'][k]+';'\n",
    "            my_tmp_cn+=OMIM_trans['OMIM_cn'][k]+';'\n",
    "    description_save_en.append(my_tmp[:-1])\n",
    "    description_save_cn.append(my_tmp_cn[:-1])\n",
    "    geneName.append(geneSymbol_uniq[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict={'Gene':geneName,'OMIM_en':description_save_en,'OMIM_cn':description_save_cn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMIM_merge=pd.DataFrame(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMIM_merge.to_csv('OMIM_08_26.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in hpo_gene_ge2ph:\n",
    "#    HPO_description=[]\n",
    "#    HPO_description_cn=[]\n",
    "#    HPO_description_merge=[]\n",
    "#    HPO_description_merge_cn=[]\n",
    "###    gene_symbol=[]\n",
    "  #  for k in range(len(HPO_phen2gene)):\n",
    "  #      if i == HPO_phen2gene['Gene_symbol'][k]:\n",
    "  #          str_tmp_ph2gen_en=HPO_phen2gene['HPO_description'][k]+ ' (' + HPO_phen2gene['HPO_id'][k] + ')'\n",
    "  #          for kk in range(len(CHPO_raw)):\n",
    "  #              if HPO_phen2gene['HPO_id'][k] == CHPO_raw['HPO_id'][kk]:\n",
    "  ##                  str_tmp_ph2gen_cn=  CHPO_raw['HPO_name'][kk] + '(' + HPO_phen2gene['HPO_id'][k] + ')'\n",
    "   #                 HPO_description_cn.append(str_tmp_ph2gen_cn)\n",
    "   #         HPO_description.append(str_tmp_ph2gen_en)\n",
    "   # for m in range(len(HPO_gene2phen)):\n",
    "   #     if i == HPO_gene2phen['Gene_symbol'][m]:\n",
    "   #         str_tmp_ge2ph_en= HPO_gene2phen['HPO_description'][m]+ ' (' + HPO_gene2phen['HPO_id'][m] + ')'\n",
    "   #         for mm in range(len(CHPO_raw)):\n",
    "   #             if HPO_gene2phen['HPO_id'][m] == CHPO_raw['HPO_id'][mm]:\n",
    "   #                 str_tmp_ge2ph_cn= CHPO_raw['HPO_name'][mm] + '(' + HPO_gene2phen['HPO_id'][m] + ')'\n",
    "   #                 HPO_description_cn.append(str_tmp_ge2ph_cn)\n",
    "   #         HPO_description.append(str_tmp_ge2ph_en)\n",
    "   # HPO_description_uniq=list(set(HPO_description))\n",
    "    #HPO_description_cn_uniq=list(set(HPO_description_cn))\n",
    "   # #print(HPO_description_uniq)\n",
    "    #tmp=''\n",
    "    #tmp_2=''\n",
    "    #for x in HPO_description_uniq:\n",
    "     #   tmp += x + ';'\n",
    "    #str_tmp=tmp[:-1]\n",
    "    #for z in HPO_description_cn_uniq:\n",
    "     #   tmp_2 += z + ';'\n",
    "   # str_tmp_cn= tmp_2[:-1]\n",
    "    #print(str_tmp)\n",
    "   # HPO_description_merge.append(str_tmp)\n",
    "   # HPO_description_merge_cn.append(str_tmp_cn)\n",
    "   # gene_symbol.append(i)\n",
    "#New_HPO_data={'Gene_symbo':gene_symbol,'HPO_en':HPO_description_merge,'HPO_cn':HPO_description_merge_cn}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### chinesed HPO database \n",
    "#HPO_cninese_description=[]\n",
    "#HPO_raw_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement datatime (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for datatime\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datatime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
